{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REFERENCE**\n",
    "\n",
    "https://bitesofcode.wordpress.com/2017/09/12/augmented-reality-with-python-and-opencv-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overall process\n",
    "\n",
    "[1] Recognize the reference flat surface\n",
    "\n",
    "[2] Estimate the homography\n",
    "\n",
    "[3] Derive from the homography the transformation from the reference surface coordinate system to the target image coordinate system.\n",
    "\n",
    "[4] Project our 3D model in the image(pixel space) and draw it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Recognizing the target surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "- Roughly speaking, this step consists in first looking in both the reference and target images for features that stand out and, in some way, describe part the object to be recognized.\n",
    "\n",
    "### Feature description\n",
    "- Once features have been found we should find a suitable representation of the information they provide.\n",
    "\n",
    "### In open cv...\n",
    "- extracting features and its descriptors via the **ORB detector** is as easy as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cv 모듈을 임포트 하고, 이미지를 넘파이 어레이 형태로 불러온다.\n",
    "import cv2\n",
    "img = cv2.imread(\"/Users/ku/img.jpeg\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find the keypints with ORB\n",
    "kp = orb.detect(img, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute the descriptors with ORB\n",
    "kp, des = orb.compute(img, kp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draw only keypoints location, not size and orientation\n",
    "img2 = cv2.drawKeypoints(img, kp, img, color=(0, 255, 0), flags=0)\n",
    "cv2.imshow('keypoints', img2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, image = capture.read()\n",
    "    cv2.imshow('Camera stream', image)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
